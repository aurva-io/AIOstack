---
title: Installation
description: This guide covers the installation of AI Observability Stack for AI agents and ML workloads in Kubernetes.
keywords:
  [
    "installation",
    "kubernetes",
    "helm",
    "ebpf",
    "monitoring",
    "ai",
    "ml",
    "observability",
  ]
---

## Prerequisites

<Step>
<StepItem title="Kubernetes Cluster Access">

You need administrative access to a Kubernetes cluster with the following specifications:

- **GKE (Google Kubernetes Engine):** Version 1.24+ with Standard or Autopilot mode
- **EKS (Amazon Elastic Kubernetes Service):** Version 1.24+
- **AKS (Azure Kubernetes Service):** Version 1.24+
- **On-premises:** Any Kubernetes distribution (kubeadm, k3s, etc.)

**Required Permissions:**

- Cluster admin privileges to create DaemonSets
- Ability to create ServiceAccounts and RBAC resources
- Permission to deploy privileged containers

Verify cluster access:

```bash
kubectl cluster-info
kubectl auth can-i create daemonsets --all-namespaces
```

</StepItem>

<StepItem title="Node Requirements">

**Linux Kernel Version:**

- Minimum: Linux kernel 5.2+
- Recommended: Linux kernel 5.8+ for optimal eBPF support
- Required: eBPF and BTF (BPF Type Format) support enabled

**Node Specifications:**

- CPU: Minimum 1 vCPU per node (2+ vCPU recommended)
- Memory: Minimum 512Mi available per node
- Storage: 1Gi free disk space for logs and temporary files

Check kernel version on nodes:

```bash
kubectl get nodes -o wide
# Or check on a specific node
kubectl debug node/NODE_NAME -it --image=busybox -- chroot /host uname -r
```

Verify eBPF support:

```bash
kubectl debug node/NODE_NAME -it --image=ubuntu -- chroot /host bash -c "ls /sys/kernel/btf/vmlinux"
```

</StepItem>

<StepItem title="Required Tools">

**Local Machine Requirements:**

- **kubectl:** Kubernetes command-line tool
- **Helm 3.8+:** For Helm-based installation
- **Git:** To clone the repository (optional)

Install kubectl:

```bash
# Linux
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# macOS
brew install kubectl

# Windows
choco install kubernetes-cli
```

Install Helm:

```bash
# Linux/macOS
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# macOS (alternative)
brew install helm

# Windows
choco install kubernetes-helm
```

Verify installations:

```bash
kubectl version --client
helm version
```

</StepItem>

<StepItem title="Network Requirements">

**Cluster Networking:**

- Container Network Interface (CNI) plugin installed
- Network policies support (recommended for security)
- Egress access to container registries

**Firewall/Security Groups:**

- Allow inbound traffic on port 7470 (metrics endpoint)
- Allow inbound traffic on port 8080 (health checks)
- Outbound HTTPS access for pulling container images

**Service Mesh Compatibility:**

- Istio: Supported with privileged containers
- Linkerd: Supported with proper annotations
- Consul Connect: Supported with CNI configuration

</StepItem>

<StepItem title="Container Runtime">

**Supported Container Runtimes:**

- **containerd:** Fully supported (recommended)
- **CRI-O:** Fully supported
- **Docker Engine:** Supported (deprecated in newer K8s versions)

Check container runtime:

```bash
kubectl get nodes -o wide
# Look at CONTAINER-RUNTIME column
```

</StepItem>

<StepItem title="Required Knowledge">

**Kubernetes Concepts:**

- Understanding of DaemonSets, ConfigMaps, and Services
- Basic knowledge of RBAC and ServiceAccounts
- Familiarity with kubectl commands

**eBPF Basics:**

- Understanding that eBPF programs run in kernel space
- Knowledge of privileged container requirements
- Awareness of security implications

**Monitoring Stack:**

- Basic understanding of Prometheus metrics
- Familiarity with Grafana dashboards (optional)
- Knowledge of observability concepts

</StepItem>
</Step>

## Installation Methods

<Step>
<StepItem title="Method 1: Helm Installation (Recommended)">

**Step 1:** Add the AI Observability Stack Helm repository

```bash
helm repo add ai-observability https://aurva-io.github.io/ai-observability-stack
helm repo update
```

**Step 2:** Create a dedicated namespace

```bash
kubectl create namespace ai-observability
```

**Step 3:** Install with default configuration

```bash
helm install ai-observability-stack ai-observability/ai-observability-stack \
  --namespace ai-observability \
  --create-namespace
```

**Step 4:** Install with custom values (recommended for production)

Create a custom values file:

```bash
cat > custom-values.yaml << 'EOF'
# AI Observability Stack Configuration
config:
  # Tracing configuration
  tracing:
    samplingRate: 1.0
    bufferSize: "64MB"

  # LLM Provider monitoring
  providers:
    openai:
      enabled: true
      trackCosts: true
    anthropic:
      enabled: true
      trackCosts: true
    huggingface:
      enabled: true

  # ML Libraries to monitor
  libraries:
    - pytorch
    - tensorflow
    - scikit-learn
    - transformers
    - langchain
    - llamaindex

# Resource configuration
resources:
  limits:
    cpu: 500m
    memory: 1Gi
  requests:
    cpu: 100m
    memory: 256Mi

# Metrics export configuration
prometheus:
  enabled: true
  port: 7470
  path: /metrics

# Health check configuration
healthCheck:
  enabled: true
  port: 8080
  path: /health

# Security context
securityContext:
  privileged: true
  runAsUser: 0
  capabilities:
    add:
      - SYS_ADMIN
      - NET_ADMIN
      - SYS_PTRACE

# Node selector (optional)
nodeSelector: {}
  # kubernetes.io/os: linux
  # node-type: monitoring

# Tolerations for specific nodes
tolerations: []
  # - key: "dedicated"
  #   operator: "Equal"
  #   value: "monitoring"
  #   effect: "NoSchedule"
EOF
```

Install with custom configuration:

```bash
helm install ai-observability-stack ai-observability/ai-observability-stack \
  --namespace ai-observability \
  --values custom-values.yaml \
  --wait --timeout=300s
```

</StepItem>

<StepItem title="Method 2: Manual Installation with kubectl">

**Step 1:** Clone the repository

```bash
git clone https://github.com/aurva-io/ai-observability-stack.git
cd ai-observability-stack
```

**Step 2:** Create namespace

```bash
kubectl create namespace ai-observability
```

**Step 3:** Apply RBAC configuration

```bash
kubectl apply -f manifests/rbac.yaml
```

**Step 4:** Create ConfigMap with configuration

```bash
cat > config.yaml << 'EOF'
tracing:
  sampling_rate: 1.0
  buffer_size: "64MB"

providers:
  openai:
    enabled: true
    track_costs: true
  anthropic:
    enabled: true
    track_costs: true
  huggingface:
    enabled: true

libraries:
  - pytorch
  - tensorflow
  - scikit-learn
  - transformers
  - langchain
  - llamaindex

export:
  prometheus:
    enabled: true
    port: 7470
  health_check:
    enabled: true
    port: 8080
EOF

kubectl create configmap ai-observability-config \
  --from-file=config.yaml=config.yaml \
  --namespace ai-observability
```

**Step 5:** Deploy the DaemonSet

```bash
kubectl apply -f manifests/daemonset.yaml -n ai-observability
```

**Step 6:** Create Service for metrics

```bash
kubectl apply -f manifests/service.yaml -n ai-observability
```

**Step 7:** (Optional) Deploy ServiceMonitor for Prometheus

```bash
kubectl apply -f manifests/servicemonitor.yaml -n ai-observability
```

</StepItem>

<StepItem title="Method 3: Kustomize Installation">

**Step 1:** Create kustomization.yaml

```bash
cat > kustomization.yaml << 'EOF'
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: ai-observability

resources:
  - https://github.com/aurva-io/ai-observability-stack/manifests

patchesStrategicMerge:
  - custom-config.yaml

configMapGenerator:
  - name: ai-observability-config
    files:
      - config.yaml
EOF
```

**Step 2:** Apply with kubectl

```bash
kubectl apply -k .
```

</StepItem>

<StepItem title="Method 4: Operator Installation">

**Step 1:** Install the AI Observability Operator

```bash
kubectl apply -f https://github.com/aurva-io/ai-observability-stack/releases/latest/download/operator.yaml
```

**Step 2:** Create AIObservabilityStack custom resource

```bash
cat > ai-stack.yaml << 'EOF'
apiVersion: observability.aurva.io/v1
kind: AIObservabilityStack
metadata:
  name: main-stack
  namespace: ai-observability
spec:
  config:
    tracing:
      samplingRate: 1.0
    providers:
      openai:
        enabled: true
        trackCosts: true
    libraries:
      - pytorch
      - tensorflow
      - transformers
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi
EOF

kubectl apply -f ai-stack.yaml
```

</StepItem>
</Step>

## Verification and Testing

<Step>
<StepItem title="Check Installation Status">

**Verify pods are running:**

```bash
kubectl get pods -n ai-observability
kubectl get daemonset -n ai-observability
```

Expected output:

```
NAME                                    READY   STATUS    RESTARTS   AGE
ai-observability-stack-xxxxx            1/1     Running   0          2m
ai-observability-stack-yyyyy            1/1     Running   0          2m
```

**Check logs for any errors:**

```bash
kubectl logs -n ai-observability -l app=ai-observability-stack --tail=50
```

</StepItem>

<StepItem title="Test Metrics Endpoint">

**Method 1: Port-forward to test locally**

```bash
# Get a pod name
POD_NAME=$(kubectl get pods -n ai-observability -l app=ai-observability-stack -o jsonpath='{.items[0].metadata.name}')

# Port forward to the metrics port
kubectl port-forward -n ai-observability pod/$POD_NAME 7470:7470
```

In another terminal, test the metrics endpoint:

```bash
curl http://localhost:7470/metrics
```

Expected output should include metrics like:

```
# HELP ai_llm_requests_total Total number of LLM API requests
# TYPE ai_llm_requests_total counter
ai_llm_requests_total{provider="openai",model="gpt-4"} 0

# HELP ai_ml_library_calls_total Total ML library function calls
# TYPE ai_ml_library_calls_total counter
ai_ml_library_calls_total{library="pytorch",function="forward"} 0
```

**Method 2: Test via Service**

```bash
# Create a test pod
kubectl run test-pod --rm -i --tty --image=curlimages/curl -- sh

# Inside the test pod:
curl http://ai-observability-stack.ai-observability.svc.cluster.local:7470/metrics
```

</StepItem>

<StepItem title="Test Health Check">

Test the health endpoint:

```bash
# Port forward health check port
kubectl port-forward -n ai-observability pod/$POD_NAME 8080:8080

# Test health endpoint
curl http://localhost:8080/health
```

Expected response:

```json
{
  "status": "healthy",
  "version": "v1.0.0",
  "ebpf_programs": {
    "http_tracer": "loaded",
    "syscall_tracer": "loaded",
    "ssl_tracer": "loaded"
  },
  "monitored_libraries": ["pytorch", "tensorflow", "transformers"],
  "active_providers": ["openai", "anthropic"]
}
```

</StepItem>

<StepItem title="Validate eBPF Program Loading">

Check if eBPF programs are loaded correctly:

```bash
# Execute on a node to check eBPF programs
kubectl debug node/NODE_NAME -it --image=ubuntu -- chroot /host bash

# Inside the debug container:
bpftool prog list | grep ai_observability
ls /sys/fs/bpf/ai_observability/
```

Check kernel logs for eBPF-related messages:

```bash
kubectl logs -n ai-observability pod/$POD_NAME | grep -i ebpf
```

</StepItem>

<StepItem title="Test with Sample AI Application">

Deploy a test application to generate some metrics:

```bash
cat > test-app.yaml << 'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-test-app
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-test-app
  template:
    metadata:
      labels:
        app: ai-test-app
    spec:
      containers:
      - name: test-app
        image: python:3.9-slim
        command: ["/bin/bash"]
        args: ["-c", "pip install openai requests && python -c \"
import openai
import requests
import time
import os

while True:
    try:
        # Simulate OpenAI API call (will be traced by eBPF)
        response = requests.post(
            'https://api.openai.com/v1/models',
            headers={'Authorization': 'Bearer fake-key'},
            json={}
        )
        print(f'API call made: {response.status_code}')
    except Exception as e:
        print(f'Expected error: {e}')

    time.sleep(30)
\""]
EOF

kubectl apply -f test-app.yaml
```

Wait a few minutes, then check metrics again:

```bash
curl http://localhost:7470/metrics | grep ai_llm_requests_total
```

</StepItem>
</Step>

## Troubleshooting

<Step>
<StepItem title="Common Issues">

**Issue: Pods stuck in Pending state**

```bash
kubectl describe pod -n ai-observability $POD_NAME
```

Common causes:

- Node doesn't meet kernel requirements
- Insufficient resources on nodes
- SecurityContext restrictions

**Issue: eBPF programs failed to load**

Check kernel config:

```bash
kubectl debug node/NODE_NAME -it --image=ubuntu -- chroot /host bash -c "
zcat /proc/config.gz | grep -i bpf
"
```

Required kernel configs:

- `CONFIG_BPF=y`
- `CONFIG_BPF_SYSCALL=y`
- `CONFIG_DEBUG_INFO_BTF=y`

**Issue: Permission denied errors**

Ensure the DaemonSet has proper privileges:

```yaml
securityContext:
  privileged: true
  runAsUser: 0
  capabilities:
    add:
      - SYS_ADMIN
      - NET_ADMIN
      - SYS_PTRACE
```

</StepItem>

<StepItem title="Debug Commands">

**Check resource usage:**

```bash
kubectl top pods -n ai-observability
kubectl describe node | grep -A5 "Allocated resources"
```

**Inspect container filesystem:**

```bash
kubectl exec -n ai-observability $POD_NAME -- ls -la /sys/fs/bpf/
kubectl exec -n ai-observability $POD_NAME -- ps aux
```

**Network connectivity test:**

```bash
kubectl exec -n ai-observability $POD_NAME -- netstat -tlnp
kubectl exec -n ai-observability $POD_NAME -- ss -tlnp
```

</StepItem>
</Step>

## Next Steps

After successful installation:

1. **Configure Prometheus** to scrape metrics from port 7470
2. **Import Grafana dashboards** from the `/dashboards` directory
3. **Set up alerting rules** for critical AI/ML metrics
4. **Review security policies** and network restrictions
5. **Monitor resource usage** and adjust limits as needed

## Getting Help

If you encounter issues:

- **Documentation:** [https://aurva-io.github.io/ai-observability-stack](https://aurva-io.github.io/ai-observability-stack)
- **GitHub Issues:** [https://github.com/aurva-io/ai-observability-stack/issues](https://github.com/aurva-io/ai-observability-stack/issues)
- **Community Slack:** [Join our community](https://slack-invite-link)
- **Email Support:** support@aurva.io

---

**Note:** The AI Observability Stack requires privileged access to load eBPF programs. Ensure your security policies allow for this requirement.

[![Deploy to Kubernetes](https://img.shields.io/badge/Deploy%20to-Kubernetes-326CE5?style=for-the-badge&logo=kubernetes)](https://github.com/aurva-io/ai-observability-stack)

## Important Information

The project's search functionality relies on the Husky's automation to build `search-data/documents.json` ensure git commit is performed to generate this file.
